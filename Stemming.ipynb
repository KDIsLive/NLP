{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202394b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming is a process ro reduce the word to its word stem \\\n",
    "#that affixes to suffices and prefixes or \n",
    "#to the roots of the words called lemma.\n",
    "#stemming is neccesery for NLU(Understanding) and NLP (Processing)\n",
    "\n",
    "#Example\n",
    "#classification problem: classify + review and -ve review based on given comments\n",
    "#stem-- Goes, Going,Gone(GO-Root word) eat, eating, eaten, ate(eat-- Root word)\n",
    "#Disadvantages of Stemming\n",
    "#History transform to histori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c378bb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eat', 'ate', 'eat', 'go', 'go', 'goe', 'final', 'histori', 'histori']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemming = PorterStemmer()\n",
    "words = [\"eats\", \"ate\", \"eating\", \"going\", \"gos\", \"goes\", \"finally\", \"history\", \"histories\"]\n",
    "print([stemming.stem(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec63a64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eat', 'ate', 'eat', 'go', 'gos', 'goe', 'finally', 'history', 'historie']\n"
     ]
    }
   ],
   "source": [
    "#Regex Stemmer class\n",
    "#It takes single regular expression  and remove any prefix or affix that matches the expression\n",
    "from nltk.stem import RegexpStemmer\n",
    "stemmer = RegexpStemmer('ing$|s$|e$|able$',  min=4)\n",
    "words = [\"eats\", \"ate\", \"eating\", \"going\", \"gos\", \"goes\", \"finally\", \"history\", \"histories\"]\n",
    "print([stemmer.stem(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ef7ea48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eat', 'ate', 'eat', 'go', 'gos', 'goe', 'final', 'histori', 'histori']\n"
     ]
    }
   ],
   "source": [
    "#Snowball Stemmer\n",
    "#Better result\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "words = [\"eats\", \"ate\", \"eating\", \"going\", \"gos\", \"goes\", \"finally\", \"history\", \"histories\"]\n",
    "print([stemmer.stem(word) for word in words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c393aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#disdvantage\n",
    "#History Going"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
